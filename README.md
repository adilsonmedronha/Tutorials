# Tutorials
Some useful DS and ML tutorials to take a look 

## Data Preparation for ML ##
 * **The importance of data preparation** in a predictive modeling machine learning project.
 * How to mark missing data and impute the missing values using **statistical imputation**.
 * How to remove redundant input variables using **recursive feature elimination**.
 * How to transform input variables with differing scales to a standard range called **normalization**.
 * How to transform categorical input variables to be numbers called **one-hot encoding**.
 * How to transform numerical variables into discrete categories called **discretization**.
 * How to use **Principal Component Analisys** to create a projection of a dataset into a lower number of dimensions.

##  Deep Learning for Natural Language Processing
 * **What natural language processing is** and the promise and impact that deep learning is having on the field.
 * How to clean and tokenize raw text data manually and use **NLTK to make it ready for modeling**.
 * How to **encode text** using the **bag-of-words** model with the scikit-learn and Keras libraries.
 * How to train a word **embedding distributed representation** of words using the Gensim library.
 * How to learn a word **embedding distributed representation as a part of fitting** a deep learning model.
 * How to use word embeddings with **convolutional neural networks** for text classification problems.
 * How to work through a **real-world sentiment analysis problem** end-to-end using deep learning methods.

 ## Imbalanced Classification
 

* The challenge of imbalanced classification is the lack of examples for the minority class and the difference in importance of classification errors across the classes.
* How to develop a spatial intuition for imbalanced classification datasets that might inform data preparation and algorithm selection.
* The failure of classification accuracy and how alternate metrics like precision, recall, and the F-measure can better summarize model performance on imbalanced datasets.
* How to delete examples from the majority class in the training dataset, referred to as data undersampling.
* How to synthesize new examples in the minority class in the training dataset, referred to as data oversampling.
* How to combine data oversampling and undersampling techniques on the training dataset, and common combinations that result in good performance.
* How to use cost-sensitive modified versions of machine learning algorithms to improve performance on imbalanced classification datasets.