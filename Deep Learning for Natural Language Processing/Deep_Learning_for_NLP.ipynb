{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Natural Language Processing\n",
    "\n",
    "***This is my notes of 7-day Mini-Course (created by Jason Brownlee) <br>*** *May have some classmates insights*\n",
    "\n",
    "This crash course is broken down into 7 lessons.\n",
    "\n",
    "Below are 7 lessons that will get you started and productive with deep learning for natural language processing in Python:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lesson 01: [Deep Learning and Natural Language](#01)\n",
    "* Lesson 02: [Cleaning Text Data](#02)\n",
    "* Lesson 03: [Bag-of-Words Model](#03)\n",
    "* Lesson 04: [Word Embedding Representation](#04)\n",
    "* Lesson 05: [Learned Embedding](#05)\n",
    "* Lesson 06: [Classifying Text](#06)\n",
    "* Lesson 07: [Movie Review Sentiment Analysis Project](#07)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='01'></a>\n",
    "## Deep Learning and Natural Language ##\n",
    "\n",
    "* NPL: automatic manipulation of natural language, like speech and text, by software.\n",
    "* Deep Learning is a subfield of ML concerned with algorithms inspired by the structure and function of the brain (ANN).\n",
    "* A nice benefit of DP is the ability to perfom automatic feature extraction from raw data (**feature learning**).\n",
    "\n",
    "10 impressive applications of deep learning\n",
    "1. **Automatic Colorization of Black and White Images** <br>\n",
    "    Generally this approach involves the use of very large convolutional neural networks and <br> supervised layers that recreate the image with the addition of color. <br>\n",
    "    The research [Learning Representations for Automatic Colorization]() <br>\n",
    "     strives to make colorization  cost-effective and less-time consuming. <br>\n",
    "    \n",
    "    *E.g., second the autor, using [Hand-colouring](https://www.reddit.com/r/Colorization/), this photo took approximately 1h30 to be done (colorized):*  <br>\n",
    "    \n",
    "    <img src=\"https://raw.githubusercontent.com/adilsonmedronha/Tutorials/main/Deep%20Learning%20for%20Natural%20Language%20Processing/images/1_reddit_post_ww1_German_soldier_colorization.png\" width=\"250\" height=\"250\" />\n",
    "    \n",
    "    With multiple applications that can benefit from automatic colorization:\n",
    "    * Historical photographs and videos\n",
    "    * Artist assistance \n",
    "    * papers: [1](https://github.com/adilsonmedronha/Tutorials/blob/main/Deep%20Learning%20for%20Natural%20Language%20Processing/papers/1_Colorful_Image_Colorization_1603-08511.pdf), [2](https://github.com/adilsonmedronha/Tutorials/blob/main/Deep%20Learning%20for%20Natural%20Language%20Processing/papers/1_Learning_Representations_for_Automatic_Colorization_1603-06668.pdf) <br> <br>\n",
    "\n",
    "    \n",
    "2. **Automatically Adding Sounds to Silent Movies** <br>\n",
    "A deep learning model associates the video frames with a database of pre-rerecorded sounds <br> in order to select a sound to play that best matches what is happening in the scene.\n",
    "    * [Video demonstration](https://youtu.be/0FW99AQmMc8) \n",
    "    * [Paper](https://github.com/adilsonmedronha/Tutorials/blob/main/Deep%20Learning%20for%20Natural%20Language%20Processing/papers/2_Visually_Indicated_Sounds_1512-08512.pdf) <br> <br>\n",
    "\n",
    "\n",
    "3. **Automatic Handwriting Generation** <br>\n",
    "    This is an interesting task, where a corpus of text is learned and from this model new text is generated, word-by-word or character-by-character.\n",
    "    * Papers: [1](https://github.com/adilsonmedronha/Tutorials/blob/main/Deep%20Learning%20for%20Natural%20Language%20Processing/papers/3_Generating_Sequences_With_1308-0850v5.pdf), [2](https://github.com/adilsonmedronha/Tutorials/blob/main/Deep%20Learning%20for%20Natural%20Language%20Processing/papers/3_Generating_Text_with_Recurrent_Neural_Networks_LANG-RNN.pdf) <br> <br>\n",
    "\n",
    "4. **Automatic Image Caption Generation** <br>\n",
    "    Generally, the systems involve the use of very large convolutional neural networks for the object detection in the photographs and then a recurrent neural network like an LSTM to turn the labels into a coherent sentence. <br>\n",
    "    Automatic image captioning is the task where given an image the system must generate a caption that describes the contents of the image.\n",
    "    * Papers: [1](https://github.com/adilsonmedronha/Tutorials/blob/main/Deep%20Learning%20for%20Natural%20Language%20Processing/papers/4_Deep_Visual_Semantic_Alignments_for_Generating_Image_Descriptions_cvpr2015.pdf), [2](https://github.com/adilsonmedronha/Tutorials/blob/main/Deep%20Learning%20for%20Natural%20Language%20Processing/papers/4_Explain_Images_with_Multimodal_Recurrent_Neural_Networks_1410-1090v1.pdf) <br> <br>\n",
    "\n",
    "5. **Sentiment analysis** <br>\n",
    "    Aspect specific sentiment analysis using hierarchical deep learning <br> <br>\n",
    "\n",
    "6. **Text classification** <br>\n",
    "    Recurrent Convolutional Neural Networks for Text Classification. <br>\n",
    "    The task is to assign a document to one or more classes or categories <br>\n",
    "    * [Paper](https://github.com/adilsonmedronha/Tutorials/blob/main/Deep%20Learning%20for%20Natural%20Language%20Processing/papers/6_Convolutional_Neural_Networks_For_Text_Classification_9745-44425-1-PB.pdf) <br> <br>\n",
    "\n",
    "7. **Named Entity Recognition** <br>\n",
    "    Neural architectures for named entity recognition. NER — sometimes referred to as entity chunking, <br> extraction, or identification — is the task of identifying and categorizing key information (entities) in text.\n",
    "    * [Paper](https://github.com/adilsonmedronha/Tutorials/blob/main/Deep%20Learning%20for%20Natural%20Language%20Processing/papers/7_Neural_Architectures_for_Named_Entity_Recognition_1603-01360.pdf) <br> <br>\n",
    "\n",
    "8. **Reading Comprehension** <br>\n",
    "    The answer to each question is a segment of text from the corresponding reading passage (Fig. 1) <br> (Stanford Researchers) we build a strong logistic regression model, which achieves an F1 score of 51.0% <br>\n",
    "    However, human performance (86.8%) is much higher.\n",
    "    * [Paper](https://github.com/adilsonmedronha/Tutorials/blob/main/Deep%20Learning%20for%20Natural%20Language%20Processing/papers/8_SQuAD_100%2C000%2B_Questions_for_Machine_Comprehension_of_Text1606-05250.pdf) <br> <br>\n",
    "\n",
    "9. **[InferKit's Text Generation](https://app.inferkit.com/demo)**\n",
    "    It is a tool takes text you provide and generates what it thinks comes next, <br>\n",
    "    using a state-of-the-art neural network. It's configurable and can produce any length of text on <br> practically any topic. An example: <br>\n",
    "        Input: <br>\n",
    "        While not normally known for his musical talent, Elon Musk is releasing a debut album <br>\n",
    "        Completion: <br>\n",
    "        While not normally known for his musical talent, Elon Musk is releasing a debut album. <br>\n",
    "        **It's called \"The Road to Re-Entry,\" and it features an astounding collection of songs... (continued)** <br> <br>\n",
    "\n",
    "10. **Pixel restoration CSI style**\n",
    "    Early in 2017, Google Brain researchers trained a Deep Learning network to take very low resolution images of faces and predict what each face most likely looks like. <br>\n",
    "    * [Paper](https://github.com/adilsonmedronha/Tutorials/blob/main/Deep%20Learning%20for%20Natural%20Language%20Processing/papers/10_Pixel_Recursive_Super_Resolution_1702-00783.pdf)\n",
    "\n",
    "\n",
    "**Additional Examples** <br>\n",
    "Below are some additional examples to those listed above:\n",
    "\n",
    "* Automatic speech recognition. <br>\n",
    "    [Deep Neural Networks for Acoustic Modeling in Speech Recognition](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38131.pdf), 2012 <br>\n",
    "* Automatic speech understanding. <br>\n",
    "    [Towards End-to-End Speech Recognition with Recurrent Neural Networks](http://proceedings.mlr.press/v32/graves14.pdf), 2014 <br>\n",
    "* Automatically focus attention on objects in images. <br>\n",
    "    [Recurrent Models of Visual Attention](https://arxiv.org/pdf/1406.6247v1.pdf), 2014 <br>\n",
    "* Automatically answer questions about objects in a photograph. <br>\n",
    "    [Exploring Models and Data for Image Question Answering](https://arxiv.org/pdf/1505.02074v4.pdf), 2015 <br>\n",
    "* Automatically turing sketches into photos. <br>\n",
    "    [Convolutional Sketch Inversion](https://arxiv.org/pdf/1606.03073.pdf), 2016 <br>\n",
    "* Automatically create stylized images from rough sketches.  <br>\n",
    "    [Neural Doodle](https://github.com/alexjc/neural-doodle) <br>\n",
    "\n",
    "**Here’s 30 impressive NLP applications using deep learning methods:** <br>\n",
    "    [It is a map with links](https://www.xmind.net/m/AEYf/). Download this and open it on XMind."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
